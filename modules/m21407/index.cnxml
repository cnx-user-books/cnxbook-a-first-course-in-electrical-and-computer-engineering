<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:md="http://cnx.rice.edu/mdml">
  <title>Binary Codes: The Communication Paradigm</title>
  <metadata>
  <md:content-id>m21407</md:content-id><md:title>Binary Codes: The Communication Paradigm</md:title>
  <md:abstract/>
  <md:uuid>c0b08c30-b3e0-4ae0-ada1-0ecf62789ac8</md:uuid>
</metadata>

<content>
    <note id="eip-595">This module is part of the collection, <emphasis effect="italics">A First Course in Electrical and Computer Engineering</emphasis>. The LaTeX source files for this collection were created using an optical character recognition technology, and because of this process there may be more errors than usual. Please contact us if you discover any errors.
</note><para id="id2258263">A <emphasis effect="italics">paradigm</emphasis> is a pattern of ideas that form the foundation for a body of knowledge. A paradigm for (tele-) communication theory is a pattern of basic building blocks that may be applied to the dual problems of (i) reliably transmitting information from source to receiver at high speed or (ii) reliably storing information from source to memory at high density. High-speed communication permits us to accommodate many low-rate sources (such as audio) or one high-rate source (such as video). High-density storage permits us to store a large amount of information in a small space. For example, a typical 1.2 Mbyte floppy disc stores <m:math overflow="scroll"><m:mrow><m:mn>9</m:mn><m:mo>.</m:mo><m:mn>6</m:mn><m:mo>×</m:mo><m:msup><m:mn>10</m:mn><m:mn>6</m:mn></m:msup></m:mrow></m:math> bits of information, whereas a typical CD stores about <m:math>
<m:mn>2</m:mn><m:mrow><m:mo>×</m:mo><m:msup><m:mn>10</m:mn><m:mn>9</m:mn></m:msup></m:mrow></m:math> bits, enough for one hour's worth of high-quality sound.</para>
    <figure id="uid1"><media id="uid1_media" alt="This is a block diagram of a telecommunications system. The diagram progresses from the upper left in a horseshoe shape to the lower left. There are four boxes on the top row labeled from left to right: source, source coder, channel coder and, modulator. lines connect all of these boxes. Underneath this row is the label (transmitter). A line proceeds from the final top row box at a right angle to a box in the middle labebeled channel. Another right angle shaped line proceeds down from this middle box the bottom row. The Bottom row is parallel to the upper row and has four boxes labeled from right to left: demodulator, channel decoder, source decoder, and destination. Above this row is the label (receiver).">
        <image mime-type="image/png" src="../../media/pic002-72d9.png" id="uid1_onlineimage" width="500"><!-- NOTE: attribute width changes image size online (pixels). original width is 229. --></image>
        <image for="pdf" mime-type="application/postscript" src="../../media/pic002-5c7e.eps" id="uid1_printimage" print-width="3.5in">
<!--NOTE: attribute width changes image size in printed PDF (if specified in .tex file)-->
        </image>
      </media>
      
    <caption>Basic Building Blocks in a (Tele-) Communication System</caption></figure>
    <para id="id2258984"><link target-id="uid1">Figure 1</link> illustrates the basic building blocks that apply to any problem in the theory of (tele-) communication. The <emphasis effect="italics">source</emphasis> is an arbitrary source of information. It can be the time-varying voltage at the output of a vibration sensor (such as an integrating accelerometer for measuring motion or a microphone for measuring sound pressure); it can be the charges stored in the CCD array of a solid-state camera; it can be the addresses generated from a sequence of keystrokes at a computer terminal; it can be a sequence of instructions in a computer program. The <emphasis effect="italics">source coder</emphasis> is a device for turning primitive source outputs into more efficient representations. For example, in a recording studio, the source coder would convert analog voltages into digital approximations using an <m:math overflow="scroll"><m:mrow><m:mi mathvariant="normal">A</m:mi><m:mo>/</m:mo><m:mi mathvariant="normal">D</m:mi></m:mrow></m:math> converter; a fancy source coder would use a fancy <m:math overflow="scroll"><m:mrow><m:mi mathvariant="normal">A</m:mi><m:mo>/</m:mo><m:mi mathvariant="normal">D</m:mi></m:mrow></m:math> converter that finely quantized likely analog values and crudely quantized unlikely values. If the source is a source of discrete symbols like letters and numbers, then a fancy source code would assign short binary sequences to likely symbols (such as <m:math>
<m:mi>e</m:mi>
</m:math>) and long binary sequences to unlikely symbols (such as <m:math>
<m:mi>z</m:mi>
</m:math>). The <emphasis effect="italics">channel coder</emphasis> adds “redundant bits” to the binary output of the source coder so that errors of transmission or storage may be detected and corrected. In the simplest example, a binary string of the form 01001001 would have an extra bit of 1 added to give <emphasis effect="italics">even parity</emphasis> (an even number of l's) to the string; the string 10110111 would have an extra bit of 0 added to preserve the <emphasis effect="italics">even parity</emphasis>. If one bit error is introduced in the channel, then the parity is odd and the receiver knows that an error has occurred. The <emphasis effect="italics">modulator</emphasis> takes outputs of the channel coder, a stream of binary digits, and constructs an analog waveform that represents a block of bits. For example, in a 9600 baud Modem, five bits are used to determine one of <m:math overflow="scroll"><m:mrow><m:msup><m:mn>2</m:mn><m:mn>5</m:mn></m:msup><m:mo>=</m:mo><m:mn>32</m:mn></m:mrow></m:math> phases that are used to modulate the signal <m:math>
<m:mi>A</m:mi>
<m:mrow><m:mo form="prefix">cos</m:mo><m:mo>(</m:mo><m:mi>ω</m:mi><m:mi>t</m:mi><m:mo>+</m:mo><m:mi>φ</m:mi><m:mo>)</m:mo></m:mrow></m:math>. Each possible string of five bits has its own personalized phase, <m:math>
<m:mi>φ</m:mi>
</m:math>, and this phase can be determined at the receiver. The signal <m:math overflow="scroll"><m:mrow><m:mi>A</m:mi><m:mo form="prefix">cos</m:mo><m:mo>(</m:mo><m:mi>ω</m:mi><m:mi>t</m:mi><m:mo>+</m:mo><m:mi>φ</m:mi><m:mo>)</m:mo></m:mrow></m:math> is an analog signal that may be transmitted over a <emphasis effect="italics">channel</emphasis> (such as a telephone line, a microwave link, or a fiber-optic cable). The channel has a finite bandwidth, meaning that it distorts signals, and it is subject to noise or interference from other electromagnetic radiation. Therefore transmitted information arrives at the <emphasis effect="italics">demodulator</emphasis> in imperfect form. The demodulator uses <emphasis effect="italics">filters</emphasis> matched to the modulated signals to demodulate the phase and look up the corresponding bit stream. The <emphasis effect="italics">channel decoder</emphasis> converts the coded bit stream into the information bit stream, and the <emphasis effect="italics">source decoder</emphasis> looks up the corresponding symbol. This sequence of steps is illustrated symbolically in Figure 7.3.</para>
    <figure id="uid2"><media id="uid2_media" alt="The is a sumbolic representation of communication. The image consist of a sequence of 0 and 1 patterns connected by arrows. The sequence starts at the upper left with a_i. An arrow proceeds to the right to 0110 then to 01100 and end the upper row with a_cos(ωt-φ[01100]). An arrow forms a right angle down and then another right angle to the left. The arrow then intersects φ then 01100 then 0110 and finally ends this bottom row at a_i.">
        <image mime-type="image/png" src="../../media/pic003-8627.png" id="uid2_onlineimage" width="500"><!-- NOTE: attribute width changes image size online (pixels). original width is 220. --></image>
        <image for="pdf" mime-type="application/postscript" src="../../media/pic003-cf13.eps" id="uid2_printimage" print-width="3.5in">
<!--NOTE: attribute width changes image size in printed PDF (if specified in .tex file)-->
        </image>
      </media>
      
    <caption>Symbolic Representation of Communication</caption></figure>
    <para id="id2259486">In your subsequent courses on communication theory you will study each block of <link target-id="uid1">Figure 1</link> in detail. You will find that every source of information has a characteristic complexity, called <emphasis effect="italics">entropy</emphasis>, that determines the minimum rate at which bits must be generated in order to represent the source. You will also find that every communication channel has a characteristic tolerance for bits, called <emphasis effect="italics">channel capacity</emphasis>. This capacity depends on signal-to-noise ratio and bandwidth. When the channel capacity exceeds the source entropy, then you can transmit information reliably; if it does not, then you cannot.
</para>
  </content>
</document>